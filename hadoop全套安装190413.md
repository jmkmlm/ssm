# Hadoop全套安装教程（20190413）

[TOC]

------



### hadoop安装

环境：

hadoop2.5

java1.8

所有操作都是在root下操作的。也可以自己定义用户名，需要为每个安装包配置权限。

```shell
#chown -R  yonghuming  /dir
```

目录：

所有安装包都按照在 /usr/local/*

所有软件包都在 /home/用户名/Dowloads

##### 1.规划ip，配置/etc/hosts

比如一个主节点为master，两个子节点为slave1，slave2

```shell
#vim /etc/hosts
192.168.1.1 master
192.168.1.2 slave1
192.168.1.3 slave2
```

##### 2.免密登录配置

![1555079843212](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555079843212.png)

master

```shell
#ssh-keygen -t rsa
#cd /root/.ssh/
#scp id_rsa.pub root@192.168.1.2:/
```

slave1

```shell
#cd /
#cat id_rsa.pub >> /root/.ssh/authorized_keys
```

![1555079598759](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555079598759.png)

以上配置仅使master访问slave1可以免密访问。还需要配置其他5条路径，这样就可以实现主节点和从节点之间互相免密登录。

**关键文件**

authorized_keys： 授权密钥，存放各个主机的公钥。也就是说每个文件中存两个id_rsa.pub

id_rsa.pub：代表每台主机的公钥，将它发送给其他节点，便于免密登录其他节点。

**注意**

如果多次生成失败后，请

```shell
#rm -rf /root/.ssh
```

然后重新操作。

##### 3.解压软件包

http://hadoop.apache.org/

https://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html

tar解压并改名java、hadoop

```shell
#cd /home/centos/Downloads/
#tar -xzvf jdk-8u101-linux-x64.tar.gz -C /usr/local/
#tar -xzvf hadoop-2.5.2.tar.gz -C /usr/local/
#mv jdk-8u101-linux-x64.tar.gz/ jdk
#mv hadoop-2.5.2.tar.gz/ hadoop
```

##### 4.临时数据目录

所有slave节点都操作

```shell
#mkdir /usr/local/workspace/hadoop/tmp
```

##### 5.配置文件

```shell
#cd /usr/local/hadoop/etc/hadoop
#ls
```

4个主要xml配置文件+2个脚本

**core-site.xml**

```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
			<property>
                <name>fs.defaultFS</name>
                <value>hdfs://master:9000</value>
            </property>                                  
            <property>
                <name>hadoop.tmp.dir</name>			                                                     <value>file:/usr/local/workspace/hadoop/tmp</value>
            </property> 
</configuration>

```

**hdfs-site.xml**

设置节点数目

设置namenode目录

设置datenode目录

设置远程连接权限不验证

```xml
<configuration>
        <property>
            <name>dfs.replication</name>
            <value>2</value>
        </property>
		<property>
            <name>dfs.namenode.name.dir</name>
            <value>file:/usr/local/workspace/hadoop/tmp/dfs/name</value>
        </property>
		<property>
            <name>dfs.datenode.date.dir</name>
            <value>file:/usr/local/workspace/hadoop/tmp/dfs/date</value>
        </property>
        <property>
            <name>dfs.permissions.enabled</name>
            <value>false</value>
        </property>    
</configuration>
```

**mapred-site.xml**

```xml
<configuration>
	<property>
		<name>mapreduce.framework.name</name>
		<value>yarn</value>
	</property>
</configuration>
```

**yarn-site.xml**

```xml
<configuration>
			<property>
			   	<name>yarn.nodemanager.aux-services</name>
			   	<value>mapreduce_shuffle</value>
			 </property>
			 <property>
			   	<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
			   	<value>org.apache.hadoop.mapred.ShuffleHandler</value>
			  </property>
			 <property>
			   	<name>yarn.resourcemanager.address</name>
			 	 <value>master:8032</value>
			  </property>
			  <property>
			   	<name>yarn.resourcemanager.scheduler.address</name>
			   	<value>master:8030</value>
			  </property>
			  <property>
			   	<name>yarn.resourcemanager.resource-tracker.address</name>
			   	<value>master:8035</value>
			  </property>
			  <property>
			   	<name>yarn.resourcemanager.admin.address</name>
			   	<value>master:8033</value>
			  </property>
			  <property>
			   	<name>yarn.resourcemanager.webapp.address</name>
			   	<value>master:8088</value>
			  </property>
</configuration>

```

**mapred-env.sh**

```shell
export JAVA_HOME=/usr/local/jdk
```

**hadoop-env.sh**

```shell
export JAVA_HOME=/usr/local/jdk
```

**将以上6个配置文件发送到各节点下覆盖。**



这个文件只在子节点配置

**slaves文件**

```shell
slave1

slave2
```



##### 6.配置全局环境变量

```shell
#vim /etc/profile
JAVA_HOME=/usr/local/jdk
HADOOP_HOME=/usr/local/hadoop                       
PATH=$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export JAVA_HOME PATH HADOOP_HOME

#source /etc/profile
```

##### 7.格式化文件系统

```shell
hdfs namenode -format
```

**保证 /usr/local/hadoop/namenode/hdfs/data和name 空一致**
**保证 /usr/local/hadoop/tmp 清空**

##### 8.启动

```shell
#start-all.sh
#jps
```

![1555083082343](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555083082343.png)

### Hive安装

##### 1.解压安装包

http://hive.apache.org/downloads.html

```shell
#cd /home/centos/Downloads/
#tar -xzvf apache-hive-0.13-bin.tar.gz -C /usr/local/
#mv apache-hive-0.13-bin.tar.gz/ hive
```

##### 2.安装并配置mysql

###### a.通过 yum 命令安装

可以先通过 yum list |grep mysql 方式查看有哪些版本的 mysql

```shell
#yum install mysql-server mysql-devel mysql
#service mysql start/service mysql stop
#mysqladmin -u root password 123456
#show variables like '%character%'   //编码
```

如果mysql-server没有被安装，按照如下教程

```shell
#wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpm
#rpm -ivh mysql-community-release-el7-5.noarch.rpm
#yum install mysql-server
```

###### b.远程连接

授权法

```shell
mysql>GRANT ALL PRIVILEGES ON *.* TO 'myuser'@'192.168.1.3'IDENTIFIED BY 'mypassword' WITH GRANT OPTION;
mysql>FLUSH PRIVILEGES
```

改表法

在localhost登入mysql后，更改 “mysql” 数据库里的 “user” 表里的 “host” 项，将"localhost"改称"%"

```shell
#mysql -u root -p
   Enter password:
    ……
mysql>update user set host = '%' where user = 'root';
mysql>select host, user from user;
```

###### c.在mysql创建用户

在mysql下创建hadoop用户，root不允许外连。

##### 4.配置Hive

###### a.新建配置文件 hive-site.xml

```shell
#cd /usr/local/hive/conf
#vim  hive-site.xml
```

 **hive-site.xml**

注意：最后一项的hadoop用户，

注意：中间mysql连接数据库的地址。

```xml
<?xml version="1.0"?> 
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?> 
<configuration> 
    <property> 
        <name>hive.metastore.local</name> 
        <value>true</value> 
    </property> 
    <property> 
        <name>javax.jdo.option.ConnectionURL</name> 
         <value>jdbc:mysql://master:3306/hive_13?characterEncoding=UTF-8</value> 
    </property> 
    <property> 
        <name>javax.jdo.option.ConnectionDriverName</name> 
        <value>com.mysql.jdbc.Driver</value> 
    </property> 
    <property> 
        <name>javax.jdo.option.ConnectionUserName</name> 
        <value>hadoop</value> 
    </property> 
    <property> 
        <name>javax.jdo.option.ConnectionPassword</name> 
        <value>hadoop</value> 
    </property> 
</configuration> 
```

##### 5.下载mysql链接驱动包

https://dev.mysql.com/downloads/connector/j/5.1.html

```shell
#cd /home/centos/Dowloads
#tar -xzvf mysql-connector-java-5.1.47.tar.gz -C /usr/local
#cp mysql-connector-java-5.1.47.tar.gz/mysql-connector-java-5.1.27-bin.jar /usr/local/hive/lib
```

##### 6.配置环境变量

```shell
#vim /etc/profile
export HIVE_HOME=/usr/local/hive 
export PATH=$PATH:$HIVE_HOME/bin 
#source /etc/profile
```

##### 7.初始化schema

由于Hive中所有的原信息都需要存储到关系型数据库里面,因此需要初始化数据库表。

```shell
#cd /usr/local/hive/bin
#./schematool -initSchema -dbType mysql
```

##### 8.测试

![1555117225197](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555117225197.png)

### Hbase安装

该部分需要在hadoop基础上，并且要求hadoop已经正常启动。

##### 1.解压安装包

http://hbase.apache.org/

```shell
#cd /home/centos/Downloads/
#tar -xzvf hbase-1.1.5-bin.tar.gz -C /usr/local/
#mv hbase-1.1.5-bin.tar.gz/ hbase
```

##### 2.配置环境变量

```shell
#vim /etc/profile
export HBASE_HOME=/usr/local/hbase
export PATH=$PATH:${HBASE_HOME}/bin
#source /etc/profile
```

##### 3.配置文件

```shell
#cd  /usr/local/hbase/conf
#vim ./hbase-site.xml
```

**hbase-site.xml**

hbase.rootdir指定HBase的分布式存储目录；

hbase.cluster.distributed设置集群处于分布式模式

```xml
<configuration>
        <property>
                <name>hbase.rootdir</name>
                <value>hdfs://master:9000/hbase</value>
        </property>
        <property>
                <name>hbase.cluster.distributed</name>
                <value>true</value>
        </property>
</configuration>
```

##### 4.测试运行

![1555119725436](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555119725436.png)

### pig安装

依赖hadoop集群

##### 1.解压安装包

http://pig.apache.org/

```shell
#cd /home/centos/Downloads/
#tar -xzvf pig-0.17.0.tar.gz -C /usr/local/
#mv pig-0.17.0.tar.gz/ pig
```

##### 2.配置环境变量

```shell
#vim /etc/profile
export PIG_HOME=/usr/local/pig
export PATH=$PIG_HOME/bin
#source /etc/profile
```

##### 3.测试

当前有两个环境：单JVM中的本地执行环境和Hadoop集群上的分布式执行环境。

***本地模式***

Grunt是Pig的外壳程序（shell）。本地模式下，Pig运行在单个JVM中，访问本地文件系统，该模式用于测试或处理小规模数据集

```shell
#pig -x local
```

![1555127013393](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555127013393.png)



***MapReduce模式***

在MapReduce模式下，Pig将查询翻译为MapReduce作业，然后在Hadoop集群上执行。

```shell
#pig -x mapreduce
```

![1555127256214](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555127256214.png)

### Sqoop安装

1.46以前为sqoop1.0

1.47以后为sqoop2.0

本教程为2.0安装教程

##### 1.解压安装包

http://sqoop.apache.org/

```shell
#cd /home/centos/Downloads/
#tar -xzvf sqoop-1.99.7-bin-hadoop200.tar.gz -C /usr/local/
#mv sqoop-1.99.7-bin-hadoop200.tar.gz/ sqoop
```

##### 2.配置文件

```shell
#cd /usr/local/sqoop/conf
#vim sqoop.properties
```

修改属性

/org.apache.sqoop.submission.engine.mapreduce.configuration.directory

指定当前的hadoop目录  /usr/local/hadoop

![1555120206553](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555120206553.png)



接下来在conf文件夹中添加catalina.properties文件,注意hadoop路径是否一致/usr/local/hadoop/

```properties
common.loader=${catalina.base}/lib,${catalina.base}/lib/*.jar,${catalina.home}/lib,${catalina.home}/lib/*.jar,${catalina.home}/../lib/*.jar,/usr/local/hadoop/share/hadoop/common/*.jar,/usr/local/hadoop/share/hadoop/common/lib/*.jar,/usr/local/hadoop/share/hadoop/hdfs/*.jar,/usr/local/hadoop/share/hadoop/hdfs/lib/*.jar,/usr/local/hadoop/share/hadoop/mapreduce/*.jar,/usr/local/hadoop/share/hadoop/mapreduce/lib/*.jar,/usr/local/hadoop/share/hadoop/tools/lib/*.jar,/usr/local/hadoop/share/hadoop/yarn/*.jar,/usr/local/hadoop/share/hadoop/yarn/lib/*.jar,/usr/local/hadoop/share/hadoop/httpfs/tomcat/lib/*.jar

```

##### 3.创建数据目录

```shell
#cd /usr/local/sqoop
#mkdir extra
#mkdir logs
```

##### 4.配置sqoop环境变量

```shell
#vim /etc/profile
export SQOOP_HOME=/usr/local/sqoop
export PATH=$PATH:$SQOOP_HOME/bin
export SQOOP_SERVER_EXTRA_LIB=$SQOOP_HOME/extra
export CATALINA_BASE=$SQOOP_HOME/server
export LOGDIR=$SQOOP_HOME/logs/
#source /etc/profile
```

##### 5.测试

**启动sqoop服务端**

![1555120736785](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555120736785.png)

**启动sqoop客户端**

![1555120834663](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555120834663.png)

### Spark安装

##### 1.解压安装包

http://spark.apache.org/downloads.html

```shell
#cd /home/centos/Downloads/
#tar -xzvf spark-1.5.2-bin-2.5.2.tgz -C /usr/local/
#mv spark-1.5.2-bin-2.5.2.tgz/ sqoop

```

##### 2.配置文件

**spark-env.sh**

在第一行添加以下配置信息:

```shell
#cd /usr/local/spark
#cp ./conf/spark-env.sh.template ./conf/spark-env.sh
#vim /conf/spark-env.sh
export SPARK_DIST_CLASSPATH=$(/usr/local/hadoop/bin/hadoop classpath)
```

##### 3.测试

![1555122062222](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555122062222.png)

![1555122076500](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555122076500.png)

### Storm安装

java安装

zooKeeper安装http://mirrors.cnnic.cn/apache/zookeeper/stable/

storm安装

#### zooKeeper

##### 1.解压安装包

zookeeper

```shell
#cd /home/centos/Downloads/
#tar -xzvf zookeeper-3.4.14.tar.gz -C /usr/local/
#mv zookeeper-3.4.14.tar.gz/ zookeeper
```

##### 2.配置文件

zooKeeper配置

```shell
#cd /usr/local/zookeeper
#mkdir tmp
#cp ./conf/zoo_sample.cfg ./conf/zoo.cfg
#vim ./conf/zoo.cfg
```

将当中的 dataDir=/tmp/zookeeper 更改为 dataDir=/usr/local/zookeeper/tmp

##### 3.测试

```shell
#./bin/zkServer.sh start
```

![1555122789555](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555122789555.png)



#### Storm

##### 1.解压安装包

```shell
#cd /home/centos/Downloads/
#tar -xzvf apache-storm-0.9.6.tar.gz -C /usr/local/
#mv apache-storm-0.9.6.tar.gz/ storm
```

##### 2.配置文件

```shell
#cd /usr/local/storm
#vim ./conf/storm.yaml
```

修改其中的 storm.zookeeper.servers 和 nimbus.host 两个配置项为127.0.0.1

![1555123011954](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555123011954.png)



##### 3.测试

先启动nimbus

```shell
#./bin/storm nimbus
```

![1555123231160](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555123231160.png)



启动 nimbus 后，终端被该进程占用了，不能再继续执行其他命令了。

因此我们需要另外开启一个终端，然后执行如下命令启动 supervisor 后台进程：

```shell
#/usr/local/storm/bin/storm supervisor
```

![1555123458566](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555123458566.png)



同样的，启动 supervisor 后，我们还需要开启**另外的终端**才能执行其他命令.

![1555123567769](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555123567769.png)

### Kafka安装

需要先启动zooKeeper

##### 1.解压安装包

```shell
#cd /home/centos/Downloads/
#tar -xzvf kafka_2.11-2.2.0.tgz -C /usr/local/
#mv kafka_2.11-2.2.0.tgz/ kafka
```

##### 2.核心概念

1. **Broker**
  Kafka集群包含一个或多个服务器，这种服务器被称为broker
2. **Topic**
  每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）
3. **Partition**
  Partition是物理上的概念，每个Topic包含一个或多个Partition.
4. **Producer**
  负责发布消息到Kafka broker
5. **Consumer**
  消息消费者，向Kafka broker读取消息的客户端。
6. **Consumer Group**
  每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）

##### 3.测试

**启动kafka服务端**：

```shell
#cd /usr/local/kafka
#bin/kafka-server-start.sh config/server.properties
```

如果启动中发现内存不足，可修改kafka-server-start.sh

```html
解决办法：
将 kafka-server-start.sh的
export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"
修改为
export KAFKA_HEAP_OPTS="-Xmx256M -Xms128M"
```

![1555124909902](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555124909902.png

![1555124829775](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555124829775.png)

以下为成功：

![1555125061570](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555125061570.png)



kafka服务端就启动了,请**千万不要关闭当前终端**。



如果误关，再次启动会失败，解决方案：

```shell
1：
 删除 /logs/kafka-logs；

2：netstat -lnp|grep 9092；并且 kill -9 pid；

3: 最后再重新启动下就ok了
 ./kafka-server-start.sh ../config/server.properties
```





启动**另外一个终端**,输入如下命令:

```shell
#cd /usr/local/kafka
#bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic dblab
```

![1555125637315](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555125637315.png)

topic是发布消息发布的category,以单节点的配置创建了一个叫dblab的topic.可以用list列出所有创建的topics,来查看刚才创建的主题是否存在。

```shell
#bin/kafka-topics.sh --list --zookeeper localhost:2181  
```

![1555125730162](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555125730162.png)

可以在结果中查看到dblab这个topic存在。

接下来用producer生产点数据：

```shell
#bin/kafka-console-producer.sh --broker-list localhost:9092 --topic dblab
```

![1555125888030](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555125888030.png)



然后再次开启新的终端或者直接按CTRL+C退出。

然后使用consumer来接收数据,输入如下命令：(端口对应为9092)

```shell
#cd /usr/local/kafka
#bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic dblab --from-beginning  
```

![1555126168925](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555126168925.png)





全套下来启动如下：

![1555126241805](C:\Users\HYT\AppData\Roaming\Typora\typora-user-images\1555127419109.png)

